<h1 id="machine-learning">Machine Learning</h1>
<ul>
<li>Grew out of work in AI</li>
<li>New capability for computers</li>
</ul>
<p>Usage Examples :</p>
<ul>
<li>Database mining</li>
</ul>
<p>Large datasets from the growth of automation/web.</p>
<ul>
<li>Applications can&#39;t program by hand.</li>
</ul>
<p>Autonomous helicopter, NLP, Computer Vision</p>
<ul>
<li>Self-customizing programs</li>
</ul>
<p>Recommendations</p>
<h2 id="definition">Definition</h2>
<ul>
<li>Arthur Samuel(1959)</li>
</ul>
<p>Field of study that gives computers the ability to learn without being explicitly programmed.</p>
<ul>
<li>Tom Mitchell(1998)</li>
</ul>
<p>A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.</p>
<p>Example: Classifying emails as spam or not.</p>
<p>Example: playing checkers.</p>
<p>E = the experience of playing many games of checkers</p>
<p>T = the task of playing checkers.</p>
<p>P = the probability that the program will win the next game.</p>
<h2 id="algorithms">Algorithms</h2>
<ul>
<li>Supervised learning</li>
<li>Unsupervised learning </li>
<li>Reinforcement learning </li>
<li>Recommender systems</li>
</ul>
<h3 id="supervised-learning">Supervised Learning</h3>
<p>Common type of machine learning program.</p>
<p>In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.</p>
<p>Supervised learning problems are categorized into &quot;regression&quot; and &quot;classification&quot; problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories.</p>
<p>Problems:</p>
<ul>
<li>Housing price prediction.<ul>
<li>Given data about the size of houses on the real estate market, try to predict their price. Price as a function of size is a continuous output, so this is a regression problem.</li>
<li>Fiting to straight line or qudaratic function.</li>
<li>We could turn this example into a classification problem by instead making our output about whether the house &quot;sells for more or less than the asking price.&quot; Here we are classifying the houses based on price into two discrete categories.</li>
</ul>
</li>
</ul>
<p>Right answers are given.
Regression Problem: Predict continuous valued output(price)</p>
<ul>
<li>Breast cancer (malignant, benign)</li>
</ul>
<p>Probality/ classification problem
Discrete valued output(0 or 1) (0,1,2,3)</p>
<p>Here we can use 1 feature or attribute such as tumor size to classify.</p>
<p>Other attibutes we may use are
    - Clump Thickness
    - Uniformity of cell size
    - uniformity of cell shape
    - age</p>
<p>If we have a problem which have the infinite no of features from which we make predictions, an algorithm called <strong>Support Vector Machine</strong>  allows us to deal with an infinite number of features.</p>
<ul>
<li><strong>Regression</strong> - Given a picture of a person, we have to predict their age on the basis of the given picture</li>
<li><strong>Classification</strong> - Given a patient with a tumor, we have to predict whether the tumor is malignant or benign.</li>
</ul>
<h3 id="unsupervised-learning">Unsupervised Learning</h3>
<p>Data does not have any labels. Can we find a find clusters in given data set.</p>
<p>Example: Google News</p>
<p>Clustering algorithms finds different categories the data falls under.</p>
<ul>
<li>Market segmentation</li>
<li>Social Network analysis</li>
<li>Astronomical data analaysis</li>
</ul>
<p>Cocktail party problem.</p>
<p>Seperate audios of different speakers</p>
<p>Examples:</p>
<ul>
<li>Given a set of news articles found on the web, group them into sets of articles about the same stories.</li>
<li>Given a database of customer data, automatically discover market segments and group customers into different market segments.</li>
</ul>
<p>Unsupervised learning allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don&#39;t necessarily know the effect of the variables.</p>
<p>We can derive this structure by clustering the data based on relationships among the variables in the data.</p>
<p>With unsupervised learning there is no feedback based on the prediction results.</p>
<p>Example:</p>
<p>Clustering: Take a collection of 1,000,000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different variables, such as lifespan, location, roles, and so on.</p>
<p>Non-clustering: The &quot;Cocktail Party Algorithm&quot;, allows you to find structure in a chaotic environment. (i.e. identifying individual voices and music from a mesh of sounds at a cocktail party).</p>
<h3 id="model-representation">Model representation</h3>
<h3 id="linear-regression-with-one-variable">Linear regression with one variable</h3>
<ul>
<li>Regression Problem -      Predict real-valued output</li>
<li>SUpervised Learning-      Given right answers for each example of data.</li>
<li>Classification Problem-   Discrete-valued outputs</li>
</ul>
<p>Training sets Notations</p>
<ul>
<li>m = No. of training examples</li>
<li>x&#39;s = input variable/features</li>
<li>y&#39;s = output variable/ target variable</li>
<li>(x,y) - One taining example</li>
<li>(x<sup>i</sup>, y<sup>i</sup>) - i<sup>th</sup>(row) training example.</li>
<li>h(hypothesis) maps froms x&#39;s to y&#39;s (Learning algorithms)</li>
<li>h<sub>&theta;</sub>(x) = &theta;<sub>0</sub> + &theta;<sub>1</sub>x </li>
</ul>
<img src="images/basic_ml.png" alt="Machine Learing basic">

<h4 id="cost-function">Cost function</h4>
<p>h<sub>&theta;</sub>(x) = &theta;<sub>0</sub> + &theta;<sub>1</sub>x </p>
<p>&theta;<sub>i</sub>&#39;s : Parameters</p>
<p>Choose &theta;<sub>0</sub>, &theta;<sub>1</sub> so that h<sub>&theta;</sub>(x) is close to y for our training examples (x,y)</p>
<p>Goal : Minimize &theta;<sub>0</sub>, &theta;<sub>1</sub> that is </p>
<p>J( &theta;<sub>0</sub>, &theta;<sub>1</sub>) = 1/2m * &Sigma; <sup>m</sup><sub>i=1</sub> (h<sub>&theta;</sub>(x) - y)<sup>2</sup></p>
<p>Minimize J( &theta;<sub>0</sub>, &theta;<sub>1</sub>) is called <strong>cost function</strong> or sometimes called <strong>squared error function</strong> or <strong>Mean squared error</strong> which is mostl commonly used for linear regression problems.</p>
<img src="images/cost_function_linear_regression.png" alt="cost_function_linear_regression">

<img src="images/cost_function_linear_regression1.png" alt="cost_function_linear_regression">

<img src="images/cost_function_linear_regression2.png" alt="cost_function_linear_regression">

<img src="images/cost_function_linear_regression3.png" alt="cost_function_linear_regression">


<p>Final goal, we should try to minimize the cost function. In this case,  &theta;<sub>1</sub>  =1 is our global minimum</p>
<p><strong>Contour Plots</strong></p>
<p>Contour plots (sometimes called Level Plots) are a way to show a three-dimensional surface on a two-dimensional plane. It graphs two predictor variables X Y on the y-axis and a response variable Z as contours. These contours are sometimes called z-slices or iso-response values.</p>
<p>A contour plot is appropriate if you want to see how some value Z changes as a function of two inputs, X and Y:
z = f(x,y).</p>
<p>A contour plot is a graph that contains many contour lines. A contour line of a two variable function has a constant value at all points of the same line. An example of such a graph is the one to the right below.</p>
<img src="images/contour1.png" alt="cost_function">

<p>Taking any color and going along the &#39;circle&#39;, one would expect to get the same value of the cost function. For example, the three green points found on the green line above have the same value for J( &theta;<sub>0</sub>, &theta;<sub>1</sub>) and as a result, they are found along the same line. The circled x displays the value of the cost function for the graph on the left when  &theta;<sub>0</sub> = 800 and &theta;<sub>1</sub> = -0.15. Taking another h(x) and plotting its contour plot, one gets the following graphs:</p>
<img src="images/contour2.png" alt="cost_function">


<p>When &theta;<sub>0</sub> = 360 and &theta;<sub>1</sub> =  0, the value of J( &theta;<sub>0</sub>, &theta;<sub>1</sub>) in the contour plot gets closer to the center thus reducing the cost function error. Now giving our hypothesis function a slightly positive slope results in a better fit of the data.</p>
<img src="images/contour3.png" alt="cost_function">

<p>The graph above minimizes the cost function as much as possible and consequently, the result of &theta;<sub>1</sub> and &theta;<sub>0</sub> tend to be around 0.12 and 250 respectively. Plotting those values on our graph to the right seems to put our point in the center of the inner most &#39;circle&#39;.</p>
