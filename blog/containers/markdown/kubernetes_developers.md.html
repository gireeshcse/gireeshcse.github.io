<h1 id="containers">Containers</h1>
<h2 id="benefits">Benefits</h2>
<ul>
<li>Accelerate Developer Onboarding </li>
<li>Eliminate App Conflicts </li>
<li>Environment Consistency</li>
<li>Ship Software Faster</li>
</ul>
<h1 id="kubernetes">Kubernetes</h1>
<p>Kubernetes (K8s) is an open-source system for automating deployment, scaling, and management of containerized applications.</p>
<h2 id="advantages">Advantages</h2>
<ul>
<li>We can package an app and we can let kubernetes to manage it for us</li>
<li>Management of containers</li>
<li>Elimination of single points of failures</li>
<li>Scales containers</li>
<li>Updates containers without bringing down the application.</li>
<li>Have a robust networking and persistent storage options.</li>
</ul>
<p><strong>Conductor of containers</strong></p>
<p><strong>Provides a declarative way to define a cluster&#39; state</strong></p>
<p><strong>Contains one or more master nodes and worker nodes(can be Physical servers,VMs).The workers nodes contains PODS which contains containers</strong></p>
<ul>
<li>POD         ----&gt; Suit</li>
<li>Container   ----&gt; Person</li>
<li>Store(etcd)(acts as a database for cluster), </li>
<li>controller manager(Takes requests and uses scheduler to perform/act upon actions),</li>
<li>API Server(To interact with the cluster to give instruction to go from one state to other&lt;--kubectl)</li>
</ul>
<p><strong>Each node has a Kubelet to communicate with the master,Container runtime to run containers within the PODs and  Kube-Proxy ensures each pod has a IP address</strong></p>
<h2 id="benefits-1">Benefits</h2>
<ul>
<li>Orchestrate Containers</li>
<li>Zero-Downtime Deployements </li>
<li>Self Healings</li>
<li>Scale Containers</li>
</ul>
<h3 id="for-developers">For Developers</h3>
<ul>
<li>Emulate production locally</li>
<li>Move from Docker Compose to Kubernetes</li>
<li>Create an end-to-end testing environment</li>
<li>To ensure application scales properly</li>
<li>To ensure secrets/config are working properly.</li>
<li>Performance testing scenarios</li>
<li>Workload scenarios(CI/CD and more)</li>
<li>Helps in learning how to leverage deployment options</li>
<li>We can Help DevOps create resources and solve problems</li>
</ul>
<h2 id="running-locally">Running Locally</h2>
<ul>
<li>Install <a href="https://kubernetes.io/docs/tasks/tools/install-minikube/">Minikude</a> </li>
<li><a href="https://www.docker.com/products/docker-desktop">Docker Desktop</a> available for Mac and Windows.</li>
</ul>
<p>Note: (To use KVM driver for ubuntu 18.04)(<a href="https://www.linuxtechi.com/install-configure-kvm-ubuntu-18-04-server/">https://www.linuxtechi.com/install-configure-kvm-ubuntu-18-04-server/</a>)</p>
<p><a href="https://minikube.sigs.k8s.io/docs/reference/drivers/">Minikube drivers</a></p>
<p>Note: sudo minikube start --vm-driver=none for Ubuntu 18.04 minikube version 1.6.2 worked <a href="https://github.com/kubernetes/minikube/releases/">minikube release</a></p>
<ul>
<li><p>To install latest minikube (Linux) Installed Binary</p>
<p>  curl -Lo minikube <a href="https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64">https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64</a> <br>  &amp;&amp; chmod +x minikube</p>
<p>  sudo install minikube /usr/local/bin/</p>
</li>
</ul>
<h2 id="minikube-commandsgenerally-requires-sudo">minikube Commands(Generally requires sudo)</h2>
<pre><code># To start a local kubernetes cluster Generally run with 
# sudo minikube --vm-driver=none if running in host directly not in VM
minikube start 
minikube stop # stop a local kubernetes cluster
minikube dashboard # access the kubernetes dashboard running within the minikube cluster
minikube delete # deletes a local kubernetes cluster
minikube start -p &lt;name&gt;&#39; to create a new cluster, or &#39;minikube delete&#39; to delete this one
minikube status</code></pre><h2 id="kubectl-commands">kubectl commands</h2>
<pre><code>    kubectl version 
    kubectl cluster-info
    kubectl get all # all info about Kubernetes Pods,Deployments,Services, and more
    kubectl run [container-name]  --image=[image-name] # simple way to create a deployment for a POD
    kubectl port-forward [pod] [ports] # forward a port to allow external access
    kubectl expose [port] # expose a port for a Deployment/Pod
    kubectl create [resource]  # create a resource
    kubectl apply [resource]  # createor modify a resource 
    kubectl --help
    kubectl get pods
    kubectl get services</code></pre><h2 id="enabling-web-ui-dashboard">Enabling Web UI Dashboard</h2>
<p><a href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/">For more Info</a></p>
<pre><code>    sudo minkube dashboard 

    or

    kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/\
    v2.0.0-beta8/aio/deploy/recommended.yaml
    kubectl describe secret -n kube-system</code></pre><p>From above command copy the token of type <strong>kubernetes.io/service-account-token</strong></p>
<pre><code>    kubectl proxy</code></pre><h3 id="error--first-record-does-not-look-like-a-tls-handshake-kubernetes">Error:  first record does not look like a tls handshake kubernetes</h3>
<p>Change (https to http)</p>
<p><a href="http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/">http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/</a></p>
<p>to </p>
<p><a href="http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/">http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/</a></p>
<h2 id="featues">Featues</h2>
<ul>
<li><p>Service discovery and load balancing </p>
<p>  Kubernetes gives Pods their own IP addresses and a single DNS name for a set of Pods, and can load-balance across them.</p>
</li>
<li><p>Storage Orchestration</p>
<p>  Automatically mount the storage system of our choice, whether from local storage, a public cloud provider such as GCP or AWS, or a network storage system such as NFS, iSCSI, Gluster, Ceph, Cinder, or Flocker.</p>
</li>
<li><p>Self Healing </p>
<p>  Restarts containers that fail, replaces and reschedules containers when nodes die, kills containers that don’t respond to your user-defined health check, and doesn’t advertise them to clients until they are ready to serve.</p>
</li>
<li><p>Automating rollouts and rollbacks</p>
<p>  Kubernetes progressively rolls out changes to your application or its configuration, while monitoring application health to ensure it doesn’t kill all your instances at the same time. If something goes wrong, Kubernetes will rollback the change for you. Take advantage of a growing ecosystem of deployment solutions.</p>
</li>
<li><p>Secret and configuration management</p>
<p>  Deploy and update secrets and application configuration without rebuilding our image and without exposing secrets in your stack configuration.</p>
</li>
<li><p>Horizontal scaling </p>
<p>  Scale your application up and down with a simple command, with a UI, or automatically based on CPU usage.</p>
</li>
</ul>
<h1 id="pods">Pods</h1>
<ul>
<li><p>A Pod is the basic execution unit of a Kubernetes application-the smallest and simplest unit in the Kubernetes object model that you create or deploy.</p>
</li>
<li><p>Pods run containers</p>
</li>
<li><p>Pods acts as a environment for containers.</p>
</li>
<li><p>As a Developer we need to organise the application &quot;parts&quot; into <strong>Pods</strong> (Server, caching, APIs, database, etc.)</p>
</li>
<li><p>Pod IP, memory, volumes, etc. shared across containers</p>
</li>
<li><p>we can scale horizontally by adding Pod replicas</p>
</li>
<li><p><strong>Pods live and die but never come back to life.</strong> New one is created</p>
</li>
<li><p>Pod containers share the same Network namespace(share IP/port)</p>
</li>
<li><p>Pod containers have the same loopback network interfaces(localhost)</p>
</li>
<li><p>Containers processes need to bind to different ports within a Pod</p>
</li>
<li><p>Ports can be reused by containers in separate Pods</p>
</li>
<li><p>Pods never span nodes</p>
</li>
</ul>
<p>Note: Pods have different ips (10.0.0.33, 10.0.0.43)</p>
<h2 id="running-a-pod">Running a Pod</h2>
<p>Use any of the following</p>
<ul>
<li><p>kubectl run command</p>
</li>
<li><p>kubectl create/apply command with a yaml file.</p>
<pre><code>  # Run the nginx:alpine container in a Pod
  kubectl run [podname]  --image=nginx:alpine
  kubectl create deployment [podname] --image=nginx:alpine

  # Examples
  kubectl run sample-nginx-alpine-pod --image=nginx:alpine # deprecated
  kubectl create deployment nginx-pod --image=nginx:alpine

  # list only pods
  kubectl get pods
  kubectl get pods --watch
  # list all resources 
  kubectl get all</code></pre></li>
</ul>
<p><strong>Pods and containers are only accessible within the kubernetes cluster by default</strong></p>
<p><strong>One way to expose a container port externally: kubectl port-forward</strong></p>
<p><strong>Image to run a pod is a docker image</strong></p>
<pre><code>    # Enable Pod Container to be 
    # called externally
    kubectl port-forward [name-of-pod]  external_port:internal_port
    kubectl port-forward pod/nginx-pod-6fc99f67cd-h4zxr  8001:80 
    # 127.0.0.1:8001 to access the application

    # will cause pod to be recreated
    kubectl delete pod [name-of-pod]
    kubectl delete pod nginx-pod-6fc99f67cd-h4zxr

    # Delete Deployment that manages the pod
    # use kubectl get all to get deployment name of the pod
    kubectl delete deployment [name-of-deployment] 
    kubectl delete deployment nginx-pod</code></pre><h3 id="yaml-review">YAML Review</h3>
<ul>
<li>Composed of maps and lists</li>
<li>Indentation matters (be consistent!)</li>
<li>Always use spaces</li>
<li>Maps:<ul>
<li>name:value pairs</li>
<li>Maps can contain other maps for more complex data structures</li>
</ul>
</li>
<li>Lists:<ul>
<li>Sequence of items</li>
<li>Multipe maps can be defined in a list</li>
</ul>
</li>
</ul>
<h4 id="example">Example</h4>
<pre><code>key: value
complexMap:
    key1: value
    key2:
    subKey: value

items:
    - item1
    - item2
    itemsMap:
    - map1: value
        map1Prop: value
    - map2: value
        map2Prop: value</code></pre><h3 id="nginxpodyml">nginx.pod.yml</h3>
<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: my-nginx
spec:
  containers:
  - name: my-nginx
    image: nginx:alpine</code></pre><h3 id="creating-a-pod-using-yaml">creating a Pod using YAML</h3>
<pre><code># perform a trial create and validate the YAML (validate true is default)
kubectl create --filename file.pod.yml --dry-run --validate=true
kubectl create -f nginx.prod.yml --dry-run --validate=true

# Create a Pod from YAML
# Will error if Pod already exists
kubectl create -f file.pod.yml

# altenative way to create or apply changes to a
# Pod from YAML
kubectl apply -f file.pod.yml
kubectl apply -f nginx.prod.yml
# above command creates a warning 
# use --save-config when you what to use 
# kubectl apply in future
kubectl create -f file.prod.yml --save-config # Store current properties in resource&#39;s annotations</code></pre><p><strong>--save-config</strong> causes the resource&#39;s configuration settings to be saved in the <strong>annotations</strong>.Having this allows in-place changes to be made to a Pod in the future using <strong>kubectl apply</strong></p>
<p>kubectl edit or kubectl patch can also be used to change small or subset of changes to a Pod.</p>
<pre><code># delete a Pod
kubectl delete pod [name-of-pod]

# delete Pod using YAML file that created it
kubectl delete -f file.pod.yml
kubectl delete -f nginx.prod.yml</code></pre><h3 id="nginxpodyml-1">nginx.pod.yml</h3>
<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: my-nginx
  labels:
    app: nginx
    rel: stable
spec:
  containers:
  - name: my-nginx
    image: nginx:alpine
    ports:
    - containerPort: 80</code></pre><p>Note: <strong>labels are used in deployments</strong></p>
<pre><code>kubectl create -f nginx.prod.yml --save-config
# shows output in YAML this is because of --save-config(added annotations to the o/p)
kubectl get pod my-nginx -o yaml 
# To trobleshoot the Pod this output is useful
kubectl describe pod [pod-name]
kubectl describe pod my-nginx
kubectl apply -f nginx.prod.yml

# to go into pod with interactive shell
kubectl exec [pod-name] -it sh
kubectl exec my-nginx -it sh # enter exit the shell

kubectl edit -f nginx.pod.yml</code></pre><h3 id="error-socat-not-found---minikube">Error socat not found - minikube</h3>
<pre><code>kubectl port-forward my-nginx 8001:80</code></pre><p><a href="https://github.com/kubernetes/minikube/issues/68#issuecomment-344346923">Solution Link</a></p>
<p>if you&#39;re running the none driver, you&#39;ll need a whole host of dependencies that kubernetes requires: docker, iptables, socat, certain kernel modules enabled, etc</p>
<p>  sudo apt-get install socat # fixed the issue.</p>
<h3 id="pod-health">Pod health</h3>
<ul>
<li>Kubernetes relies on Probes to determine the health of a Pod container.</li>
<li>A Probe is a diagnostic performed periodically by the <strong>kubelet</strong> on a container.</li>
<li>Types of Probes<ul>
<li>Liveness Probes<ul>
<li>Used to determine if a Pod is healthy and running as expected.(Should a POD is to be restarted)</li>
</ul>
</li>
<li>Readiness probes <ul>
<li>Used to determine if a Pod should receive requests.(When the traffic has to be routed to the pod)</li>
</ul>
</li>
</ul>
</li>
<li>Failed Pod containers are recreated by default (restartPolicy defaults to Always)</li>
</ul>
<p>How to check the health of the probe.It depends on the container applications.We can execute direct actions on probes.Some of them are</p>
<ul>
<li>ExecAction - Executes an action inside the container</li>
<li>HTTPGetAction - HTTP GET request against container</li>
<li>TCPSocketAction - TCP check against the containers IP address on a specified port</li>
<li>Probes can have the following results <ul>
<li>Success</li>
<li>Failure</li>
<li>Unknown</li>
</ul>
</li>
</ul>
<h4 id="defining-an-http-liveness-probe">Defining an HTTP Liveness Probe</h4>
<p>Sample Requirements</p>
<ul>
<li>Check /index.html on port 80</li>
<li>Wait 15 seconds</li>
<li>Timeout after 2 seconds</li>
<li>Check every 5 seconds</li>
<li>Alllow 1 failure before failing Pod</li>
</ul>
<h5 id="yaml-file">YAML File</h5>
<pre><code>    apiVersion: v1
    kind: Pod
    metadata:
      name: my-nginx
      labels:
        app: nginx
        rel: stable
    spec:
      containers:
      - name: my-nginx
      image: nginx:alpine
      ports:
      - containerPort: 80
      livenessProbe:
        httpGet:
          path: /index.html
          port: 80
        initialDelaySeconds: 15
        timeoutSeconds: 2 # default is 1
        periodSeconds: 5 # Default is 10
        failureThreshold: 1 # Default is 3</code></pre><h4 id="defining-an-execaction-liveness-probe">defining an ExecAction Liveness Probe</h4>
<ul>
<li>Define args for container</li>
<li>Define liveness probe</li>
<li>Define action/command to execute</li>
</ul>
<h5 id="yaml-file-1">YAML File</h5>
<pre><code>    apiVersion: v1
    kind: Pod
    metadata:
      name: busybox-liveness-pod
    spec:
      containers:
    - name: busybox-liveness-pod
      image: k8s.gcr.io/busybox
      resources:
        limits:
          memory: &quot;64Mi&quot; # 64 MB
          cpu: &quot;50m&quot; # 50 millicpu (.05 cpu or 5% of the cpu)
      args:
      - /bin/sh
      - -c
      - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600
      livenessProbe:
        exec:
          command:
          - cat
          - /tmp/healthy
        initialDelaySeconds: 5
        periodSeconds: 5</code></pre><h4 id="defining-a-readiness-probe">Defining a Readiness Probe</h4>
<ul>
<li>Define readiness probe</li>
<li>Check /index.html on port 80</li>
<li>wait 2 seconds</li>
<li>Check every 5 seconds until the probe is up and runnning.</li>
</ul>
<h5 id="yaml-file-2">YAML File</h5>
<pre><code>    apiVersion: v1
    kind: Pod
    metadata:
      name: my-nginx
      labels:
        app: nginx
        rel: stable
    spec:
      containers:
      - name: my-nginx
      image: nginx:alpine
      ports:
      - containerPort: 80
      readinessProbe:
        httpGet:
          path: /index.html
          port: 80
        initialDelaySeconds: 2
        periodSeconds: 5</code></pre><p><strong>Indetion is very important in YAML file. If any there is a problem it may result in unknown validation field error</strong></p>
<p><strong>Health checks provide a way to notify Kubernetes when a Pod has a problem</strong></p>
<h1 id="deployments">Deployments</h1>
<ul>
<li><p>A <strong>ReplicalSet</strong> is a declarative way to manage Pods.</p>
</li>
<li><p>A <strong>Deployment</strong> is a declarative way to manage Pods using a ReplicaSet.</p>
</li>
</ul>
<p>Deployments and ReplicaSets ensure Pods stay running and can be used to scale Pods.</p>
<h2 id="replicasets">ReplicaSets</h2>
<ul>
<li>Self-healing mechanism(Fault-tolerence)</li>
<li>Ensure the requested number of pods are available</li>
<li>Can be used to scale Pods (Horizontally)</li>
<li>Relies on a Pod template</li>
<li>No need to create Pods directly</li>
<li>Used by Deployments</li>
</ul>
<h2 id="deployment-manages-pods">Deployment manages Pods</h2>
<ul>
<li>Pods are managed using ReplicaSets</li>
<li>Scales ReplicaSets, which scale Pods</li>
<li>Supports zero-downtime updates by creating and destroying ReplicaSets</li>
<li>Provides rollback functionality</li>
<li>Creates a unique label that is assigned to the ReplicaSet and generated Pods</li>
<li>YAML is very similar to a ReplicaSet</li>
</ul>
<h3 id="defining-deployments-high-level">Defining Deployments (High-Level)</h3>
<pre><code>    apiVersion: apps/v1 # Kubernetes API version
    kind: Deployemnt  # Resource type
    metadata: # Metadata about the Deployment 
    spec:
      selector: # Select Pod template label(s)
      template: # template used to create the Pods
        spec:
        containers: # Containers that will run in the Pod.
        - name: my-nginx
          image: nginx:alpine</code></pre><h3 id="defining-a-deployment">Defining a Deployment</h3>
<ul>
<li><p>Kubernetes API version and resource type(Deployment)</p>
</li>
<li><p>Metadata about the Deployment </p>
</li>
<li><p>The Selector is used to &quot;select&quot; the template to use(based on labels)</p>
</li>
<li><p>Template to use to create the Pod/Containers(note that the selector matches the label)</p>
<pre><code>  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
    labels:
      app: my-nginx
      tier: frontend
  spec:
    selector:
      matchLabels:
        tier: frontend
    template:
      metadata:
        labels:
          tier: frontend
      spec:
        containers:
        - name: my-nginx
          image: nginx:alpine
          livenessProbe:
            httpGet:
              path: /index.html
              port: 80
            initialDelaySeconds: 15
            timeoutSeconds: 2
            periodSeconds: 5
            failureThreshold: 1</code></pre></li>
</ul>
<h3 id="commandskubectl--deployments">Commands(kubectl + Deployments)</h3>
<pre><code>    # Create a deployment
    kubectl create -f file.deployment.yml
    # Alternate way to create or apply changes to a 
    # Deployment from YAML
    kubectl apply -f file.deployment.yml
    # Use --save-config when you want to use
    # kubectl apply in the future
    kubectl create -f file.deployment.yml --save-config
    # List all deployments
    kubectl get deployments
    kubectl get deployments --show-labels # Deployments and their labels
    # get all deployments with a specific label
    kubectl get deployments -l app=nginx
    # Delete Deployment (All associated Pods/COntainers)
    kubectl delete deployment [deployment-name]</code></pre><h3 id="scaling-pods-horizontally">Scaling Pods Horizontally</h3>
<p>Update the YAML file or use the kubectl scale command</p>
<pre><code>    # Scale the Deployment Pods to 5
    kubectl scale deployment [deployment-name]  --replicas=5

    # Scale by refencing the YAML file
    kubectl scale -f file.deployment.yml --replicas=5

    spec:
      replicas: 3
      selector:
        tier: frontend</code></pre><h4 id="examples">Examples</h4>
<pre><code>    kubectl create -f  nginx.deployment.yml --save-config
    kubectl describe deployment my-nginx
    kubectl get deploy
    kubectl get deployment
    kubectl get deployments
    kubectl get deployments --show-labels
    kubectl get deployments -l app=nginx
    kubectl scale -f nginx.deployment.yml --replicas=3
    kubectl delete -f nginx.deployment.yml</code></pre><h4 id="yaml-file-3">YAML File</h4>
<pre><code>    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: my-nginx
    labels:
      app: my-nginx
    spec:
      replicas: 2
      selector:
        matchLabels:
        app: my-nginx
      template:
        metadata:
        labels:
            app: my-nginx
        spec:
          containers:
          - name: my-nginx
            image: nginx:alpine
            ports:
            - containerPort: 80
            resources:
            limits:
                memory: &quot;128Mi&quot; # 128 MB NO spaces between 128 and Mi
                cpu: &quot;200m&quot; # 200 millicpu (0.2 cpu or 20% of the cpu)</code></pre><h3 id="deployment-options">Deployment Options</h3>
<ul>
<li>Zero downtime deployments allow software updates to be deployed to production without impacting end users.</li>
<li>One of the strengths of Kubernetes is zero downtime deployments</li>
<li>Update an applications Pods without impacting end users</li>
<li>Several Options are availabe<ul>
<li>Rolling updates</li>
<li>Blue-green deployments(A&amp;B)(Mutiple environments are running with same environment)</li>
<li>Canary deployments (Very small amount of traffic comes to new version)</li>
<li>Rollbacks</li>
</ul>
</li>
</ul>
<h3 id="rolling-deployments">Rolling Deployments</h3>
<p>If our applications contains 3 replicas of appV1 and if we want roll to appV2, here new pods with appV2 is created and after successful creation then one of old pod is removed and this repeated until all desired nodes are created.So there zero downtime in the application.</p>
<p>Update a deployment by changing the YAML and applying changes to the cluster with kubectl apply</p>
<pre><code>    # Apply changes made in a YAML file
    kubectl apply -f file.deployment.yml

    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: node-app
    spec:
      replicas: 2
      minReadySeconds: 10
      selector:
        matchLabels:
          app: node-app
      template:
        metadata:
          labels:
            app:node-app
        spec:
          containers:
          - image: node-app:1.0
            name: node-app
            resources:</code></pre><p>Note: minReadySeconds: 10 # waits 10 seconds after container is started ensuring it didnot crash in first 10 seconds to get the traffic</p>
<p><a href="https://github.com/gireeshcse/docker-projects/tree/master/nodejs_apps_to_demonstrate_zero_downtime_kubernetes">Demo Project</a></p>
<h1 id="services">Services</h1>
<ul>
<li>A <strong>Service</strong> provides a single point of entry for accessing one or more Pods.</li>
</ul>
<p>We can&#39;t rely on IP address of Pods because these change a lot.So we need need services since Pods may only liva a short time.</p>
<p>Also Pods can be horizontally scaled so each Pod get its own IP address.</p>
<p>A Pod gets an IP address after it has been scheduled(No way for clients to know IP ahead of time)</p>
<h2 id="role-of-services">Role of services</h2>
<ul>
<li>Services abstract Pod IP addresses from consumers</li>
<li>Load balances between Pods</li>
<li>Relies on labels to associate a service with a Pod.</li>
<li>Node&#39;s kube-proxy creates a virtual IP for services</li>
<li>Uses Layer 4 (TCP/UDP over IP)</li>
<li>Services are not ephemeral(Not short lived)</li>
<li>Creates endpoints which sit between a Service and Pod</li>
<li>Services load balances the pods</li>
</ul>
<p>Note: <strong>Once the connection to Pod is established all the user requests will come to this Pod if it is alive.</strong></p>
<h2 id="service-types">Service Types</h2>
<ul>
<li>ClusterIP - Expose the service on a cluster-internal IP (Default)</li>
<li>NodePort  - Expose the service on each Node&#39;s IP at a static port.</li>
<li>LoadBalancer - Provision an external IP to act as a load balancer for the service.</li>
<li>ExternalName - Maps a service to a DNS name</li>
</ul>
<h3 id="clusterip-service">ClusterIP Service</h3>
<ul>
<li>Service IP is exposed internally within the cluster</li>
<li>Only Pods within the cluster can talk to the Service</li>
<li>Allows Pods to talk to other Pods</li>
</ul>
<h3 id="nodeport-service">NodePort Service</h3>
<ul>
<li>Exposes the service on each Node&#39;s IP at a static port.</li>
<li>Allocates a port from a range (default is 30000-32767)</li>
<li>Each Node proxies the allocated port.</li>
</ul>
<p>Helpful for testing to reach a particular Pod.</p>
<h3 id="loadbalancer-service">LoadBalancer Service</h3>
<ul>
<li>Exposes a Service externally</li>
<li>Useful when combined with a cloud provider&#39;s load balancer</li>
<li>NodePort and ClusterIP Services are created.</li>
<li>Each Node proxies the allocated port</li>
</ul>
<h3 id="externalname-service">ExternalName Service</h3>
<ul>
<li>Service that acts as an alias for an external service</li>
<li>Allows a Service to act as the Proxy for an external service</li>
<li>External service details are hidden from cluster(Easier to change)</li>
</ul>
<h1 id="storage-options">Storage Options</h1>
<h1 id="configmaps-and-secrets">ConfigMaps and Secrets</h1>
